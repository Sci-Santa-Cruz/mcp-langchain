{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84970a5-f29c-4fe2-b760-874006de9b1b",
   "metadata": {},
   "source": [
    "# Intro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d222d931-c166-4d1e-821a-a4aeb0ee5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d683ba5-9d89-42ba-8c09-4d582d85ea67",
   "metadata": {},
   "source": [
    "Cuando trabajes con el **Protocolo de Contexto de Modelo (MCP)**, normalmente estarás trabajando con (o construyendo) **clientes o servidores**. En algunos proyectos, puede que tengas la oportunidad de construir ambos. Para comprender realmente el protocolo y aprovechar todo su potencial en tus proyectos, necesitas familiarizarte con **todos los componentes de la arquitectura MCP**.\n",
    "\n",
    "En este notebook aprenderás sobre el **lado del consumidor** de esta arquitectura: las **aplicaciones host** y los **clientes**.\n",
    "\n",
    "Primero, profundizaremos en las **aplicaciones host**: qué son, qué hacen y qué tipos de aplicaciones pueden beneficiarse al incorporar MCP. Luego, examinaremos el **cliente** en sí. Esto es lo que convierte a una aplicación host en un verdadero host: **alberga uno o varios clientes**, que a su vez permiten que la aplicación host se comunique con los **servidores MCP**.\n",
    "\n",
    "Sin embargo, hay una limitación importante: **un solo cliente solo puede comunicarse con un solo servidor**. Si deseas acceder a múltiples servidores, tendrás que **iniciar varias instancias de cliente** o tener **un solo cliente que establezca conexiones breves y temporales con distintos servidores**. Analizaremos las **ventajas y desventajas** de cada enfoque, y los **casos de uso** en los que cada uno resulta más adecuado.\n",
    "\n",
    "Después, verás un **ejemplo sencillo de una aplicación host y el cliente que alberga**. Lo revisaremos **línea por línea** para que entiendas la estructura de un cliente y cómo proporciona funcionalidad a la aplicación host. Finalmente, aprenderás sobre las **mejores prácticas** para integrar un cliente dentro de una aplicación host, garantizando que tu aplicación se mantenga **segura, confiable y con buen rendimiento**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a13d9c-d3d3-42ba-9cbd-42ac5e084d4f",
   "metadata": {},
   "source": [
    "# La aplicación host\n",
    "\n",
    "Tu aplicación puede ser cualquier cosa que aloje al/los cliente(s) que gestionarán las conexiones con servidores MCP, desde un script de chatbot sencillo que recibe entrada del usuario y la envía a un LLM para obtener una respuesta, hasta un IDE con todas las funciones como Cursor o Windsurf.\n",
    "\n",
    "Gracias a la modularidad de MCP, hay muy pocas restricciones sobre lo que debe hacer tu aplicación host para soportar MCP. Solo necesita comunicarse con un LLM y alojar uno o más clientes MCP. Si planeas usar herramientas, entonces el LLM que utilice tu aplicación host también debe soportar el llamado de herramientas (tool calling).\n",
    "\n",
    "En el ejemplo a continuación verás una aplicación host mínima. En su estado actual solo toma la entrada del usuario en un bucle constante y la pasa a un LLM. Puedes encontrar este script y todo el código de este capítulo en `ch3` en el repositorio de Github del libro.\n",
    "\n",
    "Ejemplo: Una aplicación host simple\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b05d17a-dd24-462e-aa09-2aba5d63666b",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "# Leer clave API desde el entorno\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Inicializar cliente de OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"Bienvenido a tu Asistente de IA (ChatGPT). Escribe 'adiós' para salir.\")\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        prompt = input(\"Tú: \")\n",
    "        if prompt.lower() in (\"adiós\", \"adios\"):\n",
    "            print(\"Asistente de IA: ¡Adiós!\")\n",
    "            break\n",
    "\n",
    "        # Crear mensaje con el modelo GPT-4\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "\n",
    "        # Imprimir respuesta del asistente\n",
    "        print(\"Asistente:\", response.choices[0].message.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca247f-24f9-4132-b5f2-b8b6a309750a",
   "metadata": {},
   "source": [
    "Aquí tenemos los inicios de un host MCP: un script muy simple que toma la entrada del usuario, la envía a un LLM (en este caso, ChatGPT de OpenAI) y muestra la respuesta. Veámoslo línea por línea.\n",
    "\n",
    "En las líneas 1–4 importamos algunos paquetes:\n",
    "`os` para cargar variables de entorno,\n",
    "`openai` para utilizar la clase del cliente de OpenAI,\n",
    "y `dotenv` para cargar temporalmente pares clave-valor desde un archivo hacia las variables de entorno.\n",
    "\n",
    "Esto permite almacenar información sensible, como las claves de API, fuera del código, en un archivo llamado convencionalmente `.env`, con el formato `CLAVE=VALOR`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06424be-1eb1-490f-8afb-68f56eef72f2",
   "metadata": {},
   "source": [
    "___\n",
    "⚠️ **Advertencia**\n",
    "No subas tus archivos `.env` al control de versiones, ya que esto puede exponer tus claves de API al público, lo que podría provocar consecuencias como **uso no autorizado** y **costos elevados** si utilizas un modelo de pago por uso.\n",
    "\n",
    "Si lo haces por accidente, inicia sesión de inmediato en el proveedor de tu API y **revoca las claves comprometidas**.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab491fb-8349-4217-9bb0-dfb65695f1f3",
   "metadata": {},
   "source": [
    "En las líneas 6–9, la aplicación llama a `load_dotenv()`, que se encarga de **cargar las claves en las variables de entorno**, y luego obtiene la clave cargada accediendo al diccionario `os.environ`. Esa clave se usa para **instanciar el cliente de OpenAI**.\n",
    "\n",
    "Después, en la línea 11, se muestra un **mensaje de bienvenida** al usuario, y el código entra en un **bucle infinito**. La línea 14 solicita un *prompt* al usuario, mientras que las líneas 15–17 verifican si el mensaje contiene la palabra de salida. Si se encuentra, la aplicación imprime un mensaje de despedida y finaliza su ejecución.\n",
    "\n",
    "Las líneas 18–28 se encargan de la **comunicación con el modelo**. Este es un patrón que verás repetidamente al realizar llamadas a modelos LLM desde código. Desde el cliente de OpenAI se accede a la función `.chat.completions.create()`, a la cual se le pasan varios parámetros, entre ellos:\n",
    "\n",
    "* `max_tokens`, que controla el número máximo de tokens generados en la respuesta,\n",
    "* `messages`, una lista de diccionarios con los mensajes y su rol (en este caso, se establece el rol como `\"user\"` y el contenido como el *prompt* del usuario),\n",
    "* y `model`, que especifica **qué modelo** se usará para la generación.\n",
    "\n",
    "La interfaz de *chat completions* dentro de la API de OpenAI es muy potente, y la función `create()` tiene muchos otros parámetros que puedes explorar para **ajustar el estilo o tipo de respuestas** que devuelve el modelo. Puedes consultar más información en la documentación oficial de OpenAI.\n",
    "\n",
    "Finalmente, en las líneas 29–30, el código imprime el contenido de texto de la respuesta generada por el modelo y devuelta por el cliente de OpenAI.\n",
    "\n",
    "A continuación, pasaremos del cliente del modelo (OpenAI) al **cliente MCP** que nuestra aplicación alojará.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38d7b8-2b4a-4b56-8257-25eaccff9886",
   "metadata": {},
   "source": [
    "# El Cliente\n",
    "\n",
    "Cuando incorporas soporte para **MCP** en tus aplicaciones, el **cliente** es uno de los componentes más importantes que construirás y con los que trabajarás. Los clientes permiten la **comunicación entre los servidores MCP y tu aplicación**, actuando como una **interfaz** entre el servidor, tu aplicación y el modelo de lenguaje que estés utilizando.\n",
    "\n",
    "Dado que los clientes sirven como punto de conexión entre tu aplicación y los servidores MCP, **ellos deciden qué funcionalidades del servidor soportarán**. Al momento de escribir este texto, los servidores MCP pueden ofrecer a una aplicación host los siguientes elementos:\n",
    "\n",
    "* **Recursos (resources):** representan datos como archivos de texto, archivos de registro (*log files*), entre otros.\n",
    "* **Prompts.**\n",
    "* **Herramientas (tools):** fragmentos de código ejecutable que un agente o modelo puede ejecutar.\n",
    "* **Muestreo (sampling):** una forma en la que el servidor puede solicitar *chat completions* al modelo de la aplicación host.\n",
    "* **Imágenes (images).**\n",
    "* **Contexto (context):** que proporciona capacidades internas de MCP a las herramientas.\n",
    "\n",
    "Puedes aprender más sobre cada uno de estos en el **Capítulo 4: El Servidor**.\n",
    "\n",
    "Además, los clientes también pueden soportar **raíces (roots)**, que definen **límites** (por ejemplo, una ubicación específica en el sistema de archivos) dentro de los cuales los servidores conectados deben operar. Estas raíces no se aplican de forma estricta, por lo que depende del servidor respetarlas y del usuario del cliente revisar cuidadosamente los servidores antes de utilizarlos.\n",
    "\n",
    "Actualmente, MCP soporta **dos mecanismos principales de transporte**:\n",
    "\n",
    "* **Entrada/Salida Estándar (Standard Input/Output – stdio)**\n",
    "* **HTTP Transmitible (Streamable HTTP)**\n",
    "\n",
    "En este capítulo aprenderás cómo implementar soporte para cada mecanismo oficial. En el **Capítulo 5** se profundizará en la **capa de transporte**, cómo funcionan las implementaciones oficiales y cómo podrías desarrollar tu propio sistema de transporte.\n",
    "\n",
    "> **Nota**\n",
    "> Anthropic lanzó recientemente una **versión beta del conector MCP**, que promete permitir a los usuarios acceder directamente a servidores MCP remotos mediante la **API de Mensajes del SDK de Anthropic**.\n",
    "> Aunque esto podría reducir la necesidad de construir clientes personalizados, hasta el momento **solo soporta herramientas y servidores MCP remotos**, lo cual —como verás en el capítulo sobre servidores MCP— **podría representar un riesgo de seguridad**. Además, este enfoque **vincula al usuario a los modelos de Anthropic (como Claude)**, que pueden no ajustarse a todos los casos de uso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1d300-9e83-40fd-a322-c107ea430031",
   "metadata": {},
   "source": [
    "# Diseño Básico de un Cliente\n",
    "\n",
    "En MCP, un **cliente** se encarga de **toda la comunicación y conexión con un servidor**. Dado que las conexiones cliente-servidor son **uno a uno**, lo más recomendable es construir una **clase cliente**.\n",
    "\n",
    "Un cliente, como mínimo, debe poder realizar las siguientes acciones:\n",
    "\n",
    "* Conectarse a un servidor.\n",
    "* Descubrir los **recursos** del servidor.\n",
    "* Poner esos recursos a disposición de un **LLM**.\n",
    "\n",
    "Más allá de estas operaciones básicas, suele ser útil implementar también:\n",
    "\n",
    "* **Autenticación**\n",
    "* **Filtrado de recursos**\n",
    "* **Independencia de modelo**\n",
    "\n",
    "En el resto de este capítulo aprenderás cómo implementar cada una de estas características y qué aportan a tus aplicaciones. Primero, esbozaremos la **interfaz de una clase cliente**.\n",
    "\n",
    "Si sigues el repositorio de GitHub, el código de esta sección está en `client.py`, mientras que todo el código de la aplicación host está en `agent.py`. Mantendremos esta estructura durante el resto del capítulo.\n",
    "\n",
    "```python\n",
    "class MCPClient:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    async def connect(self) -> None:\n",
    "        \"\"\"\n",
    "        Conectar con el servidor definido en el constructor.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    async def get_available_tools(self) -> list[Any]:\n",
    "        \"\"\"\n",
    "        Recuperar las herramientas que el servidor ha puesto a disposición.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    async def use_tool(self, tool_name: str, tool_args: list | None = None):\n",
    "        \"\"\"\n",
    "        Dado un nombre de herramienta y opcionalmente una lista de argumentos, ejecutar la herramienta.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    async def disconnect(self) -> None:\n",
    "        \"\"\"\n",
    "        Liberar recursos utilizados.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "En esta clase se definieron las **firmas de 3 métodos**, además del constructor:\n",
    "\n",
    "* `connect()` – inicializa la conexión con el servidor. La implementación dependerá del mecanismo de transporte que elijas.\n",
    "* `get_available_tools()` – utiliza la conexión del cliente con el servidor para **recuperar las herramientas disponibles**.\n",
    "* `use_tool()` – llama a una herramienta por su nombre, pasando los argumentos proporcionados.\n",
    "\n",
    "Otro nombre válido para tu cliente podría ser **MCPServer**, como se hace en los ejemplos oficiales de Python, ya que desde la perspectiva de la aplicación host, el objeto instanciado **representaría un servidor MCP**. Esto puede ser confuso, así que en este ejemplo se eligió el nombre **MCPClient**. En tus proyectos, elige el que tenga más sentido para ti y tus usuarios.\n",
    "\n",
    "Observa que este esqueleto **empieza con soporte para herramientas (tools)**. Las herramientas son uno de los **principales primitivos de MCP** y probablemente el caso de uso más popular. Permiten dar **agencia a los agentes**, **ampliar el conocimiento de los LLMs** y mucho más. Por eso empezamos implementando el soporte de herramientas, para luego avanzar a soportar todos los diferentes recursos que un servidor MCP puede ofrecer.\n",
    "\n",
    "> **Nota:** Los tres primitivos de MCP son **tools, prompts y resources**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee77772-6bce-41b6-ad57-215947198738",
   "metadata": {},
   "source": [
    "## Inicializando el Cliente y Conectando a un Servidor\n",
    "\n",
    "Antes de escribir código, debemos pensar en **cómo queremos conectarnos a un servidor**, lo que implica decidir qué **transporte** vamos a usar.\n",
    "\n",
    "En MCP, un **transporte** es una implementación de la **capa de transporte del protocolo**, que gestiona cómo se envían los mensajes entre el cliente y el servidor.\n",
    "\n",
    "Actualmente, MCP tiene **dos implementaciones de transporte principales**:\n",
    "\n",
    "* **stdio**:\n",
    "  Adecuado cuando se espera que los servidores se ejecuten junto a la aplicación host. Usa **entradas y salidas estándar** para la comunicación entre cliente y servidor. Es el transporte más común, ya que es sencillo de implementar y la mayoría de las aplicaciones comerciales que alojan clientes MCP esperan que el usuario instale y ejecute los servidores por su cuenta.\n",
    "\n",
    "> **Nota:**\n",
    "> El SDK de Python de MCP también incluye transporte **websocket** y **HTTP Server-Sent Events (SSE)**, aunque SSE está siendo reemplazado por **Streamable HTTP**. En este capítulo nos enfocaremos en Streamable HTTP, pero los patrones que veremos junto con la guía de compatibilidad de Anthropic son suficientes para soportar ambos transportes remotos. Todos los transportes se explorarán con más detalle en el capítulo 5.\n",
    "\n",
    "* **Streamable HTTP**:\n",
    "  Ideal para aplicaciones donde los servidores MCP **no se ejecutarán necesariamente junto a la aplicación host**, como en desarrollo de plataformas o herramientas hospedadas. Por ejemplo, si los servidores MCP están desplegados en otra máquina o en la red pública, un cliente stdio **nunca podrá comunicarse** con ellos. En ese caso, necesitas implementar soporte para **Streamable HTTP**.\n",
    "\n",
    "> **Advertencia:**\n",
    "> Cualquier transporte remoto, incluyendo Streamable HTTP, **debe ser asegurado correctamente** para evitar problemas de seguridad. Esto incluye **autenticar la conexión** y **validar los encabezados de origen**.\n",
    "\n",
    "---\n",
    "\n",
    "Primero, veamos el caso más simple: **conexión vía stdio**.\n",
    "\n",
    "Al conectarte a un servidor MCP mediante stdio:\n",
    "\n",
    "* El cliente **lanza el servidor como un subproceso**.\n",
    "* Luego, **lee los mensajes desde la entrada estándar** del servidor y **envía mensajes por su salida estándar**.\n",
    "\n",
    "El SDK de Python de MCP ya incluye todas las estructuras necesarias para construir un cliente y conectarse vía stdio.\n",
    "\n",
    "Comencemos configurando el **constructor** de la clase `MCPClient`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1fc9f19-7ee5-4e85-8251-cfa85cb1130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.py\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import Any\n",
    "\n",
    "from mcp import ClientSession\n",
    "\n",
    "class MCPClient:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        command: str,\n",
    "        server_args: list[str],\n",
    "        env_vars: dict[str, str] = None\n",
    "    ) -> None:\n",
    "        self.name = name  # Nombre del cliente\n",
    "        self.command = command  # Comando para iniciar el servidor MCP\n",
    "        self.server_args = server_args  # Argumentos adicionales del servidor\n",
    "        self.env_vars = env_vars  # Variables de entorno opcionales\n",
    "        self._session: ClientSession = None  # Sesión cliente MCP\n",
    "        self._exit_stack: AsyncExitStack = AsyncExitStack()  # Gestión de recursos async\n",
    "        self._connected: bool = False  # Estado de conexión\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e0640-174e-4d5f-9050-1aedbada5531",
   "metadata": {},
   "source": [
    "En este constructor se configuran varias **propiedades importantes** que permitirán conectarse e interactuar con un servidor MCP:\n",
    "\n",
    "* **`name`**: proporciona un nombre legible para humanos al cliente instanciado. Esto es útil para **logging**, especialmente si mantienes conexiones con múltiples servidores, ya que permite identificar fácilmente el origen de cualquier registro emitido. No es obligatorio para un cliente MCP.\n",
    "\n",
    "* Los siguientes tres parámetros se usan para **configurar el servidor**:\n",
    "\n",
    "  * **`command`**: identifica el ejecutable que se ejecutará para iniciar el servidor. Normalmente, los servidores se ejecutan con **python** o **node** (o **npx** según la instalación local). Para muchos casos de uso, puede ser útil definir un **enum** para asegurar que se use un comando soportado.\n",
    "  * **`server_args`**: lista de todos los argumentos de línea de comando que se pasan al ejecutable. Esto incluye, al menos, la **ruta al archivo del servidor**. Por ejemplo, si el archivo acepta argumentos `--port 8000 --verbose`, la lista sería `[\"server.py\", \"--port\", \"8000\"]`.\n",
    "  * **`env_vars`**: diccionario de variables de entorno. Funcionan como variables de entorno normales, y podrías incluso desempaquetar las variables de entorno del sistema con `{**os.environ}`, aunque no se recomienda porque podría exponer información sensible al servidor.\n",
    "\n",
    "También se incluyen algunas propiedades “privadas” de **gestión de conexión**:\n",
    "\n",
    "* **`_session`**: mantendrá la sesión del cliente.\n",
    "* **`_exit_stack`**: gestiona los contextos de conexión asíncronos (más adelante veremos cómo).\n",
    "* **`_connected`**: evita intentar conectarse a un servidor si ya estamos conectados.\n",
    "\n",
    "El siguiente paso es implementar los métodos **`connect()`** y **`disconnect()`**, donde se utilizarán los **objetos de gestión de conexión** del SDK de Python de MCP para establecer y mantener la conexión con el servidor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fe897e-55ac-4175-8c3e-f8a8a88ef9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.py\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import Any\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
    "\n",
    "class MCPClient:\n",
    "    ...\n",
    "    async def connect(self) -> None:\n",
    "        \"\"\"\n",
    "        Conectar con el servidor definido en el constructor.\n",
    "        \"\"\"\n",
    "        if self._connected:\n",
    "            raise RuntimeError(\"El cliente ya está conectado\")\n",
    "\n",
    "        # Configurar parámetros del servidor stdio\n",
    "        server_parameters = StdioServerParameters(\n",
    "            command=self.command,\n",
    "            args=self.server_args,\n",
    "            env=self.env_vars if self.env_vars else None\n",
    "        )\n",
    "\n",
    "        # Conectar al servidor stdio, iniciando el subproceso\n",
    "        stdio_connection = await self._exit_stack.enter_async_context(\n",
    "            stdio_client(server_parameters)\n",
    "        )\n",
    "        self.read, self.write = stdio_connection\n",
    "\n",
    "        # Iniciar sesión del cliente MCP\n",
    "        self._session = await self._exit_stack.enter_async_context(\n",
    "            ClientSession(read_stream=self.read, write_stream=self.write)\n",
    "        )\n",
    "\n",
    "        # Inicializar la sesión\n",
    "        await self._session.initialize()\n",
    "        self._connected = True\n",
    "\n",
    "    async def disconnect(self) -> None:\n",
    "        \"\"\"\n",
    "        Liberar recursos utilizados y cerrar la conexión.\n",
    "        \"\"\"\n",
    "        if self._exit_stack:\n",
    "            await self._exit_stack.aclose()\n",
    "            self._connected = False\n",
    "            self._session = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a310cf-678c-49f4-99de-c12f337b7581",
   "metadata": {},
   "source": [
    "Esto puede parecer complejo, sobre todo si no tienes experiencia con **Python asíncrono**. Vamos a desglosar lo que hace el método `connect()` para hacerlo más comprensible:\n",
    "\n",
    "1. Lo primero que hace `connect()` es revisar la propiedad `_connected`. Esto **previene que se intente abrir una conexión ya existente**.\n",
    "2. Luego, se instancia un objeto **`StdioServerParameters`**, pasando las propiedades definidas en el constructor (`command`, `server_args`, `env_vars`).\n",
    "3. El resto del código crea los **procesos y conexiones necesarias** para ejecutar y usar el servidor MCP. Esto se hace mediante **`_exit_stack`**, que contiene una instancia de `AsyncExitStack`.\n",
    "\n",
    "> **Nota:**\n",
    "> `AsyncExitStack` permite **anidar manualmente context managers asíncronos** sin usar la sintaxis `async with` tradicional. Esto es ideal porque permite:\n",
    ">\n",
    "> * Agregar context managers dinámicamente al stack.\n",
    "> * Liberar **todos los recursos en orden con una sola llamada** (`aclose()`), lo que es muy útil para controlar cuándo se cierran los recursos, en lugar de depender de salir del scope de cada context manager.\n",
    "> * Ingresar a cada context manager mediante `enter_async_context()`.\n",
    "\n",
    "---\n",
    "\n",
    "**Flujo de conexión con stdio:**\n",
    "\n",
    "1. Se abre una conexión al servidor stdio, iniciando el **subproceso** donde se ejecutará la sesión MCP.\n",
    "2. Se pasa una instancia de `stdio_client` creada con `server_parameters`.\n",
    "3. Se desempaquetan los resultados en `self.read` y `self.write`, que representan los **streams de lectura y escritura** de la sesión.\n",
    "4. Se inicia la **sesión MCP** mediante otra llamada a `enter_async_context()`, esta vez con `ClientSession(read_stream=self.read, write_stream=self.write)`.\n",
    "5. La sesión se inicializa con `initialize()`, que realiza:\n",
    "\n",
    "   * La conexión real al servidor.\n",
    "   * Publica las capacidades del cliente al servidor.\n",
    "   * Verifica la versión del protocolo soportada por el servidor.\n",
    "   * Notifica al servidor que el cliente se ha inicializado correctamente.\n",
    "6. Se marca `self._connected = True`.\n",
    "\n",
    "En resumen, para **conectarse a un servidor stdio**:\n",
    "\n",
    "* Crear una instancia de `StdioServerParameters`.\n",
    "* Iniciar el **subproceso del servidor** en un contexto asíncrono.\n",
    "* Iniciar la **sesión MCP** en otro contexto anidado y guardarla en `self._session`.\n",
    "* Inicializar la sesión.\n",
    "\n",
    "El método `disconnect()` simplemente llama a `self._exit_stack.aclose()` para cerrar **todas las conexiones** en orden, y luego establece `_connected = False` y `_session = None`. Con esto, puedes **conectarte y desconectarte limpiamente** de servidores MCP usando stdio.\n",
    "\n",
    "---\n",
    "\n",
    "### Conexión con Streamable HTTP\n",
    "\n",
    "El transporte **Streamable HTTP** está diseñado principalmente para **servidores MCP remotos**. Antes se usaba HTTP + SSE, pero presentaba problemas de producción, y su soporte ha sido reemplazado por Streamable HTTP.\n",
    "\n",
    "Al conectarte a un servidor remoto mediante Streamable HTTP:\n",
    "\n",
    "* La conexión se realiza a través de **un endpoint único definido por el servidor**.\n",
    "* Las respuestas pueden ser:\n",
    "\n",
    "  * **HTTP estándar inmediato**: se obtiene al enviar un POST y no requiere conexión siempre abierta.\n",
    "  * **Respuestas SSE en streaming** (opcional): se obtienen al enviar un GET vacío y dependen de si el servidor soporta SSE.\n",
    "\n",
    "> **Nota:**\n",
    "> Aunque Streamable HTTP reemplaza HTTP + SSE, **obtener una respuesta SSE es opcional**:\n",
    ">\n",
    "> * El cliente debe solicitar explícitamente la respuesta en streaming.\n",
    "> * El servidor puede elegir si la soporta o no.\n",
    "\n",
    "En el siguiente paso, implementaremos un **cliente MCP que soporte Streamable HTTP** para conectarse a servidores remotos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07321b4-5477-4111-af79-02ef6ac3287e",
   "metadata": {},
   "source": [
    "Para soportar **Streamable HTTP**, nos enfocaremos nuevamente en construir el **constructor**, `connect()` y `disconnect()` de la clase `MCPClient`. Empecemos con el constructor:\n",
    "\n",
    "```python\n",
    "# client.py\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import Callable\n",
    "\n",
    "from mcp import ClientSession\n",
    "\n",
    "class MCPClient:\n",
    "    def __init__(self, name: str, server_url: str) -> None:\n",
    "        self.name = name\n",
    "        self.server_url = server_url\n",
    "        self._session: ClientSession = None\n",
    "        self._exit_stack = AsyncExitStack()\n",
    "        self._connected: bool = False\n",
    "        self._get_session_id: Callable[[], str] = None\n",
    "```\n",
    "\n",
    "Este constructor es muy similar al del cliente stdio. Como **no se inicia un proceso local**, no necesitamos `command` ni `server_args`, pero sí necesitamos la ubicación del servidor, que proporciona `server_url`. El resto de las propiedades son las mismas que en el cliente stdio.\n",
    "\n",
    "---\n",
    "\n",
    "La conexión y desconexión del servidor también es muy similar a lo que se hace con el cliente stdio:\n",
    "\n",
    "```python\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "class MCPClient:\n",
    "    ...\n",
    "    async def connect(self, headers: dict | None = None) -> None:\n",
    "        if self._connected:\n",
    "            raise RuntimeError(\"Client is already connected\")\n",
    "\n",
    "        # Conectar al servidor Streamable HTTP\n",
    "        streamable_connection = await self._exit_stack.enter_async_context(\n",
    "            streamablehttp_client(url=self.server_url, headers=headers)\n",
    "        )\n",
    "        self.read, self.write, self._get_session_id = streamable_connection\n",
    "\n",
    "        # Iniciar sesión MCP\n",
    "        self._session = await self._exit_stack.enter_async_context(\n",
    "            ClientSession(read_stream=self.read, write_stream=self.write)\n",
    "        )\n",
    "\n",
    "        # Inicializar sesión\n",
    "        await self._session.initialize()\n",
    "        self._connected = True\n",
    "\n",
    "    async def disconnect(self) -> None:\n",
    "        \"\"\"\n",
    "        Liberar recursos y cerrar la conexión.\n",
    "        \"\"\"\n",
    "        if self._exit_stack:\n",
    "            await self._exit_stack.aclose()\n",
    "            self._connected = False\n",
    "            self._session = None\n",
    "```\n",
    "\n",
    "La principal diferencia con el cliente stdio es que aquí **se puede pasar un parámetro opcional `headers`** junto con `server_url` a `streamablehttp_client()`. Además, la función devuelve un **callback `_get_session_id`**, que permite recuperar un session ID del servidor si lo soporta, útil para **reanudar sesiones interrumpidas**. No se necesita instanciar `StdioServerParams` porque `streamablehttp_client()` recibe directamente la URL y los headers.\n",
    "\n",
    "Otros parámetros relevantes para un desarrollador de clientes:\n",
    "\n",
    "* **timeout**: tiempo en segundos para que las operaciones HTTP expiren (tipo `datetime.timedelta`, por defecto 30s).\n",
    "* **sse_read_timeout**: tiempo en segundos para esperar un evento adicional antes de expirar (tipo `datetime.timedelta`, por defecto 5 min).\n",
    "* **auth**: maneja autenticación (`httpx.auth`).\n",
    "\n",
    "Finalmente, para integrar este cliente en una aplicación host, se puede usar un **chatbot simplificado**, instanciando un cliente MCP (stdio o Streamable HTTP) y conectándose a un servidor ficticio que provea herramientas de calculadora como `add_two_numbers`, `subtract_two_numbers`, `multiply_two_numbers` y `divide_two_numbers`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd361d15-7e17-4517-9102-f1cd417b9369",
   "metadata": {},
   "source": [
    "Para adaptar tu ejemplo a **Streamable HTTP**, los cambios principales están en cómo se instancia el cliente y cómo se conecta al servidor, ya que no necesitamos lanzar un proceso local con `uv` o `python`. El resto del flujo del chatbot se mantiene igual. Aquí te muestro un ejemplo traducido y adaptado:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Suponiendo que MCPClient ya está implementado para Streamable HTTP\n",
    "mcp_client = MCPClient(\n",
    "    name=\"calculator_server_connection\",\n",
    "    server_url=\"https://my-mcp-server.example.com\"\n",
    ")\n",
    "\n",
    "print(\"Bienvenido a tu Asistente de IA. Escribe 'adiós' para salir.\")\n",
    "\n",
    "async def main():\n",
    "    # Conectar al servidor remoto\n",
    "    await mcp_client.connect(headers={\"Authorization\": \"Bearer <YOUR_TOKEN>\"})\n",
    "    \n",
    "    while True:\n",
    "        prompt = input(\"Tú: \")\n",
    "        if prompt.lower() in (\"adiós\", \"adios\"):\n",
    "            print(\"Asistente de IA: ¡Adiós!\")\n",
    "            break\n",
    "\n",
    "        message = anthropic_client.messages.create(\n",
    "            max_tokens=4096,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"claude-sonnet-4-0\",\n",
    "        )\n",
    "\n",
    "        for response in message.content:\n",
    "            print(f\"Asistente: {response.text}\")\n",
    "\n",
    "    # Desconectar del servidor\n",
    "    await mcp_client.disconnect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555fcec-6fb2-4d13-b0da-153d3b9d36bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (google-adk)",
   "language": "python",
   "name": "google-adk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
